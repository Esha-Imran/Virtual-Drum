{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <font style=\"color:rgb(100,109,254)\">   Creating  a Virtual Drum </font> </center>\n",
    "\n",
    "In this notebook we will make another cool application, this time we will play drums virtually meaning we will hit non existent drums in the air and it will play their respective sounds. \n",
    "\n",
    "The steps to produce this application are:\n",
    "\n",
    "1. *Find the color range of the target object and save it.*\n",
    "2. *Apply the correct morphological operations to reduce noise.*\n",
    "3. *Detect and track the object with contour detection.*\n",
    "4. *Extract ROI's of Instruments.*\n",
    "5. *Loading file names for sounds.*\n",
    "6. *Playing the virtual drum with a single stick.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\">  Finding Color range of target Drum sticks and saving it  </font>\n",
    "\n",
    "First and foremost we must find an appropriate color range for our target colored object , this range will be used in cv2.inrange() function to filter our object. We will also save our range array as .npy in our disk so we can access it later. Below function is the same as we have used in our color models notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150, 127, 64], [179, 255, 255]]\n"
     ]
    }
   ],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    " \n",
    "#cap = cv2.VideoCapture(2,cv2.CAP_DSHOW)\n",
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "cap.set(3,1280)\n",
    "cap.set(4,720)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    " \n",
    "cv2.createTrackbar(\"L - H\", \"Trackbars\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"L - S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L - V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U - H\", \"Trackbars\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"U - S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U - V\", \"Trackbars\", 255, 255, nothing)\n",
    " \n",
    " \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip( frame, 1 ) \n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    " \n",
    "    l_h = cv2.getTrackbarPos(\"L - H\", \"Trackbars\")\n",
    "    l_s = cv2.getTrackbarPos(\"L - S\", \"Trackbars\")\n",
    "    l_v = cv2.getTrackbarPos(\"L - V\", \"Trackbars\")\n",
    "    u_h = cv2.getTrackbarPos(\"U - H\", \"Trackbars\")\n",
    "    u_s = cv2.getTrackbarPos(\"U - S\", \"Trackbars\")\n",
    "    u_v = cv2.getTrackbarPos(\"U - V\", \"Trackbars\")\n",
    " \n",
    "    # set the lower and upper range according to the value selected by the trackbar.\n",
    "    lower_range = np.array([l_h, l_s, l_v])\n",
    "    upper_range = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    # filter and get the binary mask, where white represents your target color.\n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    " \n",
    "    # optionally you can also show the real part of the target color\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    mask_3 = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # stack all frames and show it\n",
    "    stacked = np.hstack((mask_3,frame,res))\n",
    "    cv2.imshow('Trackbars',cv2.resize(stacked,None,fx=0.4,fy=0.4))\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "    if key == ord('s'):\n",
    "        thearray = [[l_h,l_s,l_v],[u_h, u_s, u_v]]\n",
    "        print(thearray)\n",
    "        \n",
    "        # Also save this array as drum.npy\n",
    "        np.save('media/m12/drumval',thearray)\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\">  Maximizing the Detection Mask and Getting rid of the noise  </font>\n",
    "Now you may have noticed that there is some noise in the above program, this can easily be removed by morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable determines if we want to load color range from memory or use the ones defined in notebook. \n",
    "useload = True\n",
    "\n",
    "# If true then load color range from memory\n",
    "if useload:\n",
    "    drumval = np.load('media/m12/drumval.npy')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# kernel for morphological operations\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    # Take each frame and flip it\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # If you're reading from memory then load the upper and lower ranges from there\n",
    "    if useload:\n",
    "            lower_range = drumval[0]\n",
    "            upper_range = drumval[1]\n",
    "            \n",
    "    # Otherwise define your own custom values for upper and lower range.\n",
    "    else:             \n",
    "       lower_range  = np.array([150,70,173])\n",
    "       upper_range = np.array([179,189,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    \n",
    "    # perform the morphological operations to get rid of the noise\n",
    "    mask = cv2.erode(mask,kernel,iterations = 1)\n",
    "    mask = cv2.dilate(mask,kernel,iterations = 2)\n",
    "\n",
    "   \n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    mask_3 = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # stack all frames and show it\n",
    "    stacked = np.hstack((mask_3,frame,res))\n",
    "    cv2.imshow('Trackbars',cv2.resize(stacked,None,fx=0.8,fy=0.8))\n",
    "    \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\">Tracking The Target Drum Sticks   </font>\n",
    "Now that we have got a decent mask we can use it detect our drum sticks using contour detection, in fact we will draw a bonding box around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable determines if we want to load color range from memory or use the ones defined in notebook. \n",
    "useload = True\n",
    "\n",
    "# If true then load color range from memory\n",
    "if useload:\n",
    "    penval = np.load('media/m12/drumval.npy')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# kernel for morphological operations\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "# set the window to autosize so we can view this full screen.\n",
    "cv2.namedWindow('image', cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# this threshold is used to filter noise, the contour area must be bigger than this to qualify as an actual contour.\n",
    "noiseth = 500\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    # Take each frame and flip it\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # If you're reading from memory then load the upper and lower ranges from there\n",
    "    if useload:\n",
    "            lower_range = penval[0]\n",
    "            upper_range = penval[1]\n",
    "            \n",
    "    # Otherwise define your own custom values for upper and lower range.\n",
    "    else:             \n",
    "       lower_range  =  np.array([150,70,173])\n",
    "       upper_range =  np.array([179,189,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    \n",
    "    # perform the morphological operations to get rid of the noise\n",
    "    mask = cv2.erode(mask,kernel,iterations = 1)\n",
    "    mask = cv2.dilate(mask,kernel,iterations = 2)\n",
    "    \n",
    "    # detect contour.\n",
    "    contours, hierarchy = cv2.findContours(mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Make sure there was a contour present and also its size was bigger than some threshold.\n",
    "    if contours and cv2.contourArea(max(contours, key = cv2.contourArea)) > noiseth:\n",
    "        \n",
    "        # grab the biggest contour\n",
    "        c = max(contours, key = cv2.contourArea)\n",
    "        \n",
    "        # Draw a bounding box around it.\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)        \n",
    "\n",
    "    cv2.imshow('image',frame)\n",
    "    \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font style=\"color:rgb(134,19,348)\"> Thresholding the required stage and extracting ROI's of Instruments   </font>\n",
    "Now I have an image of a drum set, it has a white background so I'm going to remove it, you will need different threshold values for your particular image (If you plan to use a different image). Also in this script I'm going to extract the ROI of the instruments and print them out, alternatively you could also save them in an array and use them in the later script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd1 = 480 # Height of our web cam feed\n",
    "wd1 = 640 # width of our web cam feed\n",
    "\n",
    "drum2left = cv2.imread('media/M12/drumpics/drumcanvas.png')\n",
    "resized_drum = cv2.resize(drum2left, (wd1, hd1))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('image', cv2.WINDOW_FULLSCREEN)\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip( frame, 1 ) \n",
    "    if ret:\n",
    "                \n",
    "        gray_img = cv2.cvtColor(resized_drum,cv2.COLOR_BGR2GRAY)\n",
    "        _ , mask = cv2.threshold(gray_img, 247, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        img_bg = cv2.bitwise_and(frame,frame,mask = mask_inv)\n",
    "\n",
    "        img_fg = cv2.bitwise_and(resized_drum,resized_drum,mask = mask)\n",
    "        combined = cv2.add(img_bg,img_fg)\n",
    "             \n",
    "    cv2.imshow('image',combined)\n",
    "    k = cv2.waitKey(1) \n",
    "    if k == ord('q'):\n",
    "        break\n",
    "        #cv2.imwrite('roombak.jpg',frame)\n",
    "    elif k == ord(\"c\"):\n",
    "            r = cv2.selectROI(combined)   # r gives cols, rows, width and height in this order           \n",
    "            print(int(r[1]),int(r[1]+r[3]), int(r[0]),int(r[0]+r[2]))\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\">  Loading file names for sounds   </font>\n",
    "So in my folder drum sounds I have two sub folder called, drums and rings, these stores the mp3 files of drum sounds and ring sounds respectively.\n",
    "\n",
    "You could also specify the path manually but I'm just reading from the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['media/M12/drumsounds/ringsound\\\\drum1ring.wav', 'media/M12/drumsounds/ringsound\\\\drum2ring.wav', 'media/M12/drumsounds/ringsound\\\\drum3ring.wav', 'media/M12/drumsounds/ringsound\\\\drum4ring.wav']\n",
      "['media/M12/drumsounds/drums\\\\drum7beat.wav', 'media/M12/drumsounds/drums\\\\drum8beat.wav', 'media/M12/drumsounds/drums\\\\zdrum2soft.wav', 'media/M12/drumsounds/drums\\\\zdrum5beat.wav']\n"
     ]
    }
   ],
   "source": [
    "# python module which finds all pathnames matching a defined pattern\n",
    "import glob\n",
    "\n",
    "drumsl =[] \n",
    "ringsl = []\n",
    "\n",
    "for filename in glob.glob('media/M12/drumsounds/ringsound/*.wav'): \n",
    "    ringsl.append(filename)\n",
    "print(ringsl)    \n",
    "\n",
    "for filename in glob.glob('media/M12/drumsounds/drums/*.wav'): \n",
    "    drumsl.append(filename)\n",
    "print(drumsl)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(134,19,348)\">  Determine if the Stick is Hitting the Drum or Not:  </font>\n",
    "This function below takes x,y coordinates of the drumstick and the list or ROIs of drums and determines if the x,y are inside any of the rois, if it is then found = True and idx contains the index of the roi, so we will only play the selected drum which is inside that roi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_roi(x,y,listd):\n",
    "    found = False\n",
    "    for idx, it in enumerate(listd):\n",
    "        if y > it[0] and y < it[1] and x > it[2] and x < it[3]:\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    return found,idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(134,19,348)\">Play sounds with playsound    </font>\n",
    "So playsound is a cross platform python audio library, you can play sounds stored in disk with this. Install it by: \n",
    "\n",
    "```\n",
    "pip install playsound\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "# Playing sound normally\n",
    "playsound('media/M12/drumsounds/ringsound\\\\drum1ring.wav')\n",
    "print(\"Hello world\")\n",
    "\n",
    "# Playing sound asynchronously\n",
    "playsound('media/M12/drumsounds/ringsound\\\\drum1ring.wav', False)\n",
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(134,19,348)\"> Playing the drum with a single Stick   </font>\n",
    "\n",
    "Now there is a problem, we want to play the sound when the drumstick x,y is under ROI of any of the drums,rings but we also want to play this sound asynchronously otherwise the camera feed will freeze/pause for the audio to complete and we don't want that, but the trouble here is that by playing asynchronously we don't hear the completion of any sound, as we have a good fps the Async is executed fast enough that each sound is override by the same sound in the next iteration of the loop and the sound never completes.\n",
    "\n",
    "To solve this problem we can have a boolean variable called touching which is made `True` when the drum stick is touching drums i.e x,y are inside drum ROI and is made `False` again when the drum stick is not inside the ROI. So once the sound is played and touching becomes `True`, the user has to pull the drum out of the ROI to make touching `False` so the sound can be played again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd1 = 480 \n",
    "wd1 = 640\n",
    "useload = True\n",
    "\n",
    "if useload:\n",
    "    drumval = np.load('media/M12/drumval.npy')\n",
    "\n",
    "# These are the list of ROIs for the drums and the rings.\n",
    "d1 = [[368, 480, 182, 273] , [368, 480, 348 ,441], [348, 480, 2 , 117] ,  [343, 480, 513, 640]]\n",
    "r1 = [ [80 ,163 ,2 ,80] , [2 ,50 ,144 ,231]   ,  [0 ,49 ,385 ,486] ,  [88 ,156 ,564 ,640]]\n",
    "\n",
    "# Variable which is True when drumstick is in cotact with an ROI\n",
    "touching = False\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "drum2left =  cv2.imread('media/M12/drumpics/drumcanvas.png')\n",
    "resized_drum = cv2.resize(drum2left, (wd1, hd1))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('image2', cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "gray_img = cv2.cvtColor(resized_drum,cv2.COLOR_BGR2GRAY) \n",
    "_ , mask_background = cv2.threshold(gray_img, 247, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip( frame, 1 ) \n",
    "    if ret:\n",
    "        \n",
    "        # Convert BGR to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # If you're reading from memory then load the upper and lower ranges from there\n",
    "        if useload:\n",
    "                lower_range = drumval[0]\n",
    "                upper_range = drumval[1]\n",
    "\n",
    "        # Otherwise define your own custom values for upper and lower range.\n",
    "        else:             \n",
    "           lower_range  = np.array([150,70,173])\n",
    "           upper_range = np.array([179,189,255])\n",
    "\n",
    "        mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "\n",
    "        # perform the morphological operations to get rid of the noise\n",
    "        mask = cv2.erode(mask,kernel,iterations = 1)\n",
    "        mask = cv2.dilate(mask,kernel,iterations = 2)\n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Make sure there was a contour present and also its size was bigger than some threshold.\n",
    "        if len(contours) > 0 and cv2.contourArea(max(contours, key = cv2.contourArea)) > 450:\n",
    "            \n",
    "            # Grab the biggest contour\n",
    "            cnt = max(contours, key = cv2.contourArea)\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            \n",
    "            # get the midpoint of the drum\n",
    "            midx = int(x+(w/2))\n",
    "            midy = int(y +(h/2))\n",
    "            \n",
    "            #Optionally You can track the drums\n",
    "            #cv2.circle(frame,(midx,midy), 5, (0,255,0), -1)\n",
    "            #cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            \n",
    "            # check if midpoints are inside the drums ROI\n",
    "            found,index   = inside_roi(midx,midy,d1)\n",
    "            \n",
    "            # if the point lied inside thedrum roi then play the sound of that instrument using the index\n",
    "            if found:\n",
    "                # Only play if toucing was previously false\n",
    "                if touching == False:\n",
    "                    playsound(drumsl[index], False)\n",
    "                    touching = True\n",
    "\n",
    "            else:\n",
    "                # if the mid point was not inside drum roi then check if they are inside the rings ROI\n",
    "                found,index   = inside_roi(midx,midy,r1)\n",
    "                if found:\n",
    "                    \n",
    "                    if touching == False:\n",
    "                        playsound(ringsl[index],False)\n",
    "                        touching = True\n",
    "                        \n",
    "                else:\n",
    "                    touching = False\n",
    "\n",
    " \n",
    "        img_bg = cv2.bitwise_and(frame,frame,mask = cv2.bitwise_not(mask_background))\n",
    "        img_fg = cv2.bitwise_and(resized_drum,resized_drum,mask =mask_background)\n",
    "        combined = cv2.add(img_bg,img_fg)\n",
    "      \n",
    "\n",
    "    cv2.imshow('image2',combined)\n",
    "    k = cv2.waitKey(1) \n",
    "    if k == ord('q'):\n",
    "        break\n",
    "                \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: You can combine the drums and rings in a single list instead of working with two separate lists, I just two lists while experimenting with different types of sounds**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
